{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I8QssBIKFtAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader, DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "IdcTM24qFs9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "aDj6GhNRjU0P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pdf_file(data):\n",
        "  loader = DirectoryLoader(data,\n",
        "                           glob=\"*.pdf\",\n",
        "                           loader_cls=PyPDFLoader)\n",
        "\n",
        "  documents = loader.load()\n",
        "  return documents"
      ],
      "metadata": {
        "id": "4J5Dfa26Fs1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_data = load_pdf_file()  #have to give path of file"
      ],
      "metadata": {
        "id": "fooIhTJInJp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#After load files now split it into chunks\n",
        "def split_text(extracted_data):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
        "                                                 chunk_overlap=20)\n",
        "  text_chunks = text_splitter.split_documents(data)\n",
        "  return text_chunks"
      ],
      "metadata": {
        "id": "pFzHsUsLSaDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_chunks = text_split(extracted_data)\n",
        "print(\"Length of Text Chunks\", len(text_chunks))"
      ],
      "metadata": {
        "id": "geX4WMFbntd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "QwecRfPb1VXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_hugging_face_embedding():\n",
        "  emdeddings = HuggingFaceEmbeddings(model_name=\"sentence_transformers/all-MiniLM-L6-v2\")\n",
        "  return emdeddings"
      ],
      "metadata": {
        "id": "Z8QmLWjprH9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = download_hugging_face_embedding()"
      ],
      "metadata": {
        "id": "iZjHchYrSJ7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_result = embeddings.embed_query(\"Hello All\")\n",
        "print(\"Length\", len(query_result))"
      ],
      "metadata": {
        "id": "HTH3D-w0SJmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "tMGY4PmH169W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY=os.environ.get('PINECONE_API_KEY')\n",
        "GROQ_API_KEY=os.environ.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "Pbdd6B_T17vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone.grpc import PineconeGrpc as Pinecone\n",
        "from pinecone import ServerlessSpec\n",
        "import os\n",
        "\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "\n",
        "index_name = medbot\n",
        "\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=384,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(\n",
        "        cloud=\"aws\",\n",
        "        region=\"us-east-1\"\n",
        "    )\n",
        ")\n",
        "\n",
        "print(response)"
      ],
      "metadata": {
        "id": "I1oMYskUk327"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ],
      "metadata": {
        "id": "Km7kpQ5y2TcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_pinecone import PineconeVectorStore\n",
        "\n",
        "docsearch = PineconeVectorStore.from_documents(documents=text_chunks,\n",
        "                                               embeddings=embeddings,\n",
        "                                               index_name=index_name)"
      ],
      "metadata": {
        "id": "uf5epTa7nSzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#embed each chunk and upsert the embedding into pinecone index\n",
        "docsearch = PineconeVectorStore.from_existing_index(embeddings=embeddings,\n",
        "                                                    index_name=index_name)"
      ],
      "metadata": {
        "id": "qA1B1U3inSl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = docsearch.as_retriever(search_type=\"similarity\",search_kwargs={\"k\": 3})"
      ],
      "metadata": {
        "id": "SeNWzZm-qLP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Nh-_w_fX2i3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import Groq\n",
        "\n",
        "llm = Groq(temperature=0.4, max_tokens=500)"
      ],
      "metadata": {
        "id": "7vE4BxvZqLCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_core import ChatPromptTemplate\n",
        "\n",
        "system_prompt = (\n",
        "\"You are an assistant for question-answering tasks.\"\n",
        "\"Use the following pieces of retrieved context to answer\"\n",
        "\"the question. If you don't know the answer, say that you \"\n",
        "\"don't know. Use three sentences maximum and keep the \"\n",
        "\"answer concise.\"\n",
        "\"\\n\\n\"\n",
        "\"{context}\"\n",
        ")\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages\n",
        "\n",
        "  [\n",
        "\n",
        "    (\"system\", system_prompt),\n",
        "\n",
        "    (\"human\", \"{input}\"),\n",
        "\n",
        "  ]"
      ],
      "metadata": {
        "id": "HpunOvpVt82W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
      ],
      "metadata": {
        "id": "-RRTq6LswSeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JoCGRg2BwSPP"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "k3weXUBfo1w3",
        "outputId": "51b040eb-58ef-43ed-bb56-920284a9d1cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e44e30aa-3150-49ac-b49a-2f34b1146722\", \"downloaded_folder.zip\", 11155598)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nnR6DHfF5RR5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}